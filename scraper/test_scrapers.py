#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¬å›æ•°æ®çˆ¬è™«æµ‹è¯•è„šæœ¬
"""
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ  scraper ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from scrapers.base_scraper import BaseScraper
from scrapers.aptamil_scraper import AptamilScraper
from scrapers.feihe_scraper import FeiheScraper
from scrapers.friso_scraper import FrisoScraper
from scrapers.a2_scraper import A2Scraper
from scrapers.jinlingguan_scraper import JinlingguanScraper


def test_scraper(scraper_class, brand_name: str):
    """æµ‹è¯•å•ä¸ªçˆ¬è™«"""
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•çˆ¬è™«: {brand_name}")
    print(f"{'='*70}")

    try:
        scraper = scraper_class()
        print(f"âœ… çˆ¬è™«å®ä¾‹åŒ–æˆåŠŸ")
        print(f"   å“ç‰Œ: {scraper.brand}")
        print(f"   å“ç‰Œè‹±æ–‡å: {scraper.brand_en}")

        # æµ‹è¯•æŠ“å–
        print(f"\nå¼€å§‹æŠ“å–...")
        products = scraper.scrape()

        print(f"\næŠ“å–ç»“æœ:")
        print(f"   æˆåŠŸ: {len(products) > 0}")
        print(f"   äº§å“æ•°é‡: {len(products)}")

        if len(products) > 0:
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªäº§å“çš„ä¿¡æ¯
            print(f"\nç¬¬ä¸€ä¸ªäº§å“ç¤ºä¾‹:")
            print(f"   äº§å“åç§°: {products[0].get('product_name', 'N/A')}")
            print(f"   å­å“ç‰Œ: {products[0].get('sub_brand', 'N/A')}")
            print(f"   è§„æ ¼: {products[0].get('pack_size', 'N/A')}")
            print(f"   æ‰¹æ¬¡å·: {products[0].get('batch_codes', 'N/A')}")

            # æµ‹è¯•æ ¼å¼åŒ–
            print(f"\næµ‹è¯•æ ¼å¼åŒ–...")
            records = scraper.format_for_feishu(products, "https://example.com")
            print(f"   æ ¼å¼åŒ–è®°å½•æ•°: {len(records)}")

            print(f"\nç¬¬ä¸€ä¸ªè®°å½•ç¤ºä¾‹:")
            r = records[0]
            print(f"   å“ç‰Œ: {r.get('brand', 'N/A')}")
            print(f"   äº§å“åç§°: {r.get('product_name', 'N/A')}")
            print(f"   æ‰¹æ¬¡å·: {r.get('batch_codes', 'N/A')}")
            print(f"   åœ°åŒº: {r.get('region', 'N/A')}")
            print(f"   é£é™©ç­‰çº§: {r.get('risk_level', 'N/A')}")

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_all_scrapers():
    """æµ‹è¯•æ‰€æœ‰çˆ¬è™«"""
    print(f"\n{'='*70}")
    print("å¬å›æ•°æ®çˆ¬è™« - æ‰¹é‡æµ‹è¯•")
    print(f"{'='*70}")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    scrapers = [
        (AptamilScraper, "çˆ±ä»–ç¾"),
        (FeiheScraper, "é£é¹¤"),
        (FrisoScraper, "ç¾ç´ ä½³å„¿"),
        (A2Scraper, "a2è‡³åˆ"),
        (JinlingguanScraper, "é‡‘é¢†å† ")
    ]

    results = []

    for scraper_class, brand_name in scrapers:
        success = test_scraper(scraper_class, brand_name)
        results.append({
            "brand": brand_name,
            "success": success
        })

    # æ‰“å°æ±‡æ€»
    print(f"\n{'='*70}")
    print("æµ‹è¯•æ±‡æ€»")
    print(f"{'='*70}")

    success_count = sum(1 for r in results if r["success"])
    fail_count = len(results) - success_count

    for result in results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {result['brand']}")

    print(f"\næ€»è®¡: {len(results)} ä¸ªçˆ¬è™«")
    print(f"æˆåŠŸ: {success_count}")
    print(f"å¤±è´¥: {fail_count}")

    if fail_count == 0:
        print(f"\nğŸ‰ æ‰€æœ‰çˆ¬è™«æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {fail_count} ä¸ªçˆ¬è™«æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—")


def test_single_brand(brand_name: str):
    """æµ‹è¯•å•ä¸ªå“ç‰Œ"""
    brand_map = {
        "aptamil": (AptamilScraper, "çˆ±ä»–ç¾"),
        "feihe": (FeiheScraper, "é£é¹¤"),
        "friso": (FrisoScraper, "ç¾ç´ ä½³å„¿"),
        "a2": (A2Scraper, "a2è‡³åˆ"),
        "jinlingguan": (JinlingguanScraper, "é‡‘é¢†å† ")
    }

    if brand_name.lower() not in brand_map:
        print(f"âŒ æœªæ‰¾åˆ°å“ç‰Œ: {brand_name}")
        print(f"å¯ç”¨å“ç‰Œ: {', '.join(brand_map.keys())}")
        return

    scraper_class, name = brand_map[brand_name.lower()]
    test_scraper(scraper_class, name)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='å¬å›æ•°æ®çˆ¬è™«æµ‹è¯•')
    parser.add_argument('--brand', type=str, help='æµ‹è¯•å•ä¸ªå“ç‰Œï¼ˆå¦‚ï¼šaptamil, feihe, friso, a2, jinlingguanï¼‰')
    parser.add_argument('--all', action='store_true', help='æµ‹è¯•æ‰€æœ‰å“ç‰Œ')

    args = parser.parse_args()

    if args.brand:
        test_single_brand(args.brand)
    elif args.all:
        test_all_scrapers()
    else:
        print("è¯·æŒ‡å®š --brand æˆ– --all")
        parser.print_help()


if __name__ == "__main__":
    main()
